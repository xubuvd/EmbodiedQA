# EmbodiedQA
Embodied Question Answering (EmbodiedQA), in a 3D environment moving beyond a static image context, requires to move into a right location for answering a given question. It is combination of Visual Language Navigation (VLN) task and Visual Question answering (VQA) task. And it poses several challenge problems.<br>

# About me
虚步, a Ph.D. student at BUPT. I am very fortunate to be advised by my advisor. My research is in the area of Vision, Language, and Reasoning, with a focus on Visual Dialogue. I am particularly interested in building a visually-grounded conversational AI (social robot) that can see the world and talk with us in natural language. Other interests include Visual/Language Grounding, Visual Reasoning, Visual Question Generation, and Visually-grounded Referring Expression.<br>
<br>
Now I've been working on the EmbodiedQA problem. Please feel free to contact me with pangweitf@bupt.edu.cn or pangweitf@163.com if you have any questions or concerns.<br>

# In progress...

# Performance

# Training

# References
1. Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh and Dhruv Batra. Embodied Question Answering. In CVPR 2018.<br>
2. ...<br>
